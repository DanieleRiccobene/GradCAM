# -*- coding: utf-8 -*-
"""NewGradCam(Last)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oYuc1_RFgL2mlEIY9BGO1D_2DEzVl35a
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

danielericcobene_imagenet5_path = kagglehub.dataset_download('danielericcobene/imagenet5')
danielericcobene_imagenet_5_path = kagglehub.dataset_download('danielericcobene/imagenet-5')

print('Data source import complete.')

print(danielericcobene_imagenet_5_path)

import os
import torch
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Subset, random_split
import torchvision.transforms as transforms

# Percorso dataset
dataset_path = '/root/.cache/kagglehub/datasets/danielericcobene/imagenet-5/versions/1/imagenet-5/imagenet-5'

# Trasformazioni
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Carica tutto il dataset (tutte le immagini, tutte le classi)
full_dataset = ImageFolder(root=dataset_path, transform=transform)

# Definisci percentuale train/val
train_ratio = 0.8
train_size = int(train_ratio * len(full_dataset))
val_size = len(full_dataset) - train_size

# Split random (con seed per riproducibilità)
torch.manual_seed(42)
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

print(f"Train dimensions: {len(train_dataset)}")
print(f"Validation dimensions: {len(val_dataset)}")
print(f"Classi: {full_dataset.classes}")

import torch.nn as nn
import torchvision.models as models


def create_model(num_classes=3):
    model = models.resnet18(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_m1 = create_model(num_classes=3).to(device)

print(model_m1)

# Ottimizzatore e loss
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_m1.parameters(), lr=1e-3)

def train(model, dataloader, optimizer, criterion, device):
    model.train()
    total_loss = 0.0
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(dataloader)
    return avg_loss

def evaluate(model, dataloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct / total

for epoch in range(10):
    train_loss = train(model_m1, train_loader, optimizer, criterion, device)
    val_accuracy = evaluate(model_m1, val_loader, device)
    print(f"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Val Accuracy: {val_accuracy*100:.2f}%")

!pip install torchcam

model_resnet50 = models.resnet50(pretrained=True)
model_resnet50 = model_resnet50.to(device)
model_resnet50.eval()

from torchcam.methods import GradCAM

cam_m1 = GradCAM(model_m1, target_layer="layer4")
cam_resnet50 = GradCAM(model_resnet50, target_layer="layer4")

def generate_cam_batch(model, cam_extractor, images, device, target_labels=None, use_pred=True):
    model.eval()
    cams = []

    for i in range(images.size(0)):
        image = images[i].unsqueeze(0).to(device)
        output = model(image)

        if use_pred:
            target_class = output.argmax(dim=1).item()
        else:
            if target_labels is None:
                raise ValueError("target_labels must be provided if use_pred=False")
            target_class = target_labels[i].item()

        activation_map = cam_extractor(target_class, output)
        cams.append(activation_map[0].cpu().detach())

    return cams

pip install git+https://github.com/Arhosseini77/SUM.git

!python inference_dataset.py \
    --dataset_path /root/.cache/kagglehub/datasets/danielericcobene/imagenet-5/versions/1/imagenet-5/imagenet-5 \
    --output_path /content/saliency_maps \
    --heat_map_type Overlay

import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF

def show_gradcam_saliency(img_tensor, cam1, cam2, sal1, sal2, class_name=""):
    # img_tensor: [3, H, W]
    img = TF.to_pil_image(img_tensor.cpu())
    img_np = np.array(img)

    cam1_np = cam1.detach().cpu().numpy()
    cam2_np = cam2.detach().cpu().numpy()
    #sal1_np = sal1.detach().cpu().numpy()
    #sal2_np = sal2.detach().cpu().numpy()
    sal1_np = np.array(sal1)
    sal2_np = np.array(sal2)

    fig, axs = plt.subplots(2, 3, figsize=(12, 8))
    fig.suptitle(f'Class: {class_name}', fontsize=16)

    # RIGA 1: MODELLO M1
    axs[0, 0].imshow(img_np)
    axs[0, 0].set_title('Original Image')
    axs[0, 1].imshow(img_np)
    axs[0, 1].imshow(cam1_np, cmap='jet', alpha=0.5)
    axs[0, 1].set_title('GradCAM - M1')
    axs[0, 2].imshow(sal1_np)
    axs[0, 2].set_title('Saliency Map')

    # RIGA 2: MODELLO RESNET50
    axs[1, 0].imshow(img_np)
    axs[1, 0].set_title('Original Image')
    axs[1, 1].imshow(img_np)
    axs[1, 1].imshow(cam2_np, cmap='jet', alpha=0.5)
    axs[1, 1].set_title('GradCAM - R50')
    axs[1, 2].imshow(sal2_np)
    axs[1, 2].set_title('Saliency Map')

    for ax in axs.flat:
        ax.axis('off')

    plt.tight_layout()
    plt.show()

import os
from torchvision import transforms
from PIL import Image
import torch.nn.functional as F
import torch

# Funzioni utili
def binarize_cam(cam, threshold=0.3):
    return (cam > threshold).float()

def iou(cam1, cam2):
    intersection = torch.logical_and(cam1.bool(), cam2.bool()).sum().float()
    union = torch.logical_or(cam1.bool(), cam2.bool()).sum().float()
    if union == 0:
        return 0.0
    return (intersection / union).item()

# Configura trasformazioni e path
saliency_path = '/content/saliency_maps'
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Crea dizionario con le saliency "_overlay"
saliency_dict = {}
for class_folder in os.listdir(saliency_path):
    class_path = os.path.join(saliency_path, class_folder)
    for fname in os.listdir(class_path):
        if "_overlay" in fname:
            base = fname.replace("_overlay.png", "")
            saliency_dict[base] = os.path.join(class_path, fname)

iousm1 = []
iousr50 = []

for batch_idx, (images, labels) in enumerate(val_loader):
    images = images.to(device)
    labels = labels.to(device)

    # CAMs
    cams_m1 = generate_cam_batch(model_m1, cam_m1, images, device, target_labels=labels, use_pred=False)
    cams_r50 = generate_cam_batch(model_resnet50, cam_resnet50, images, device, target_labels=labels, use_pred=False)

    # Recupera indici assoluti degli elementi del batch nel dataset originale
    batch_indices = val_dataset.indices[batch_idx * val_loader.batch_size : (batch_idx + 1) * val_loader.batch_size]

    for i in range(min(3, len(images))):  # Visualizza solo i primi 3
        idx = batch_indices[i]
        img_path = full_dataset.samples[idx][0]
        img_name = os.path.splitext(os.path.basename(img_path))[0]

        if img_name not in saliency_dict:
            continue

        # Carica la mappa di salienza SUM
        sal_img1 = Image.open(saliency_dict[img_name])
        sal_img = Image.open(saliency_dict[img_name]).convert('L')
        sal_tensor = transform(sal_img).to(device).squeeze()
        sal_bin = binarize_cam(sal_tensor).to(device)

        cam1_resized = F.interpolate(cams_m1[i].unsqueeze(0), size=(224,224), mode='bilinear', align_corners=False).squeeze()
        cam2_resized = F.interpolate(cams_r50[i].unsqueeze(0), size=(224,224), mode='bilinear', align_corners=False).squeeze()

        cam1_bin = binarize_cam(cam1_resized).to(device)
        cam2_bin = binarize_cam(cam2_resized).to(device)

        iou_scorem1 = iou(cam1_bin, sal_bin)
        iousm1.append(iou_scorem1)

        iou_scorer50 = iou(cam2_bin, sal_bin)
        iousr50.append(iou_scorer50)

        lbl = labels[i]
        img = images[i]

        class_name = full_dataset.classes[lbl.item()]

        # ✅ CHIAMATA ALLA FUNZIONE DI VISUALIZZAZIONE
        show_gradcam_saliency(
            img_tensor=img,
            cam1=cam1_resized,
            cam2=cam2_resized,
            sal1=sal_img1,
            sal2=sal_img1,
            class_name=class_name
        )

    break

# Calcolo medie
avg_iou_m1 = sum(iousm1) / len(iousm1)
avg_iou_r50 = sum(iousr50) / len(iousr50)

print(f"Media IoU M1 vs SUM: {avg_iou_m1:.4f}")
print(f"Media IoU ResNet50 vs SUM: {avg_iou_r50:.4f}")

