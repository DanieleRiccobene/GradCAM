# -*- coding: utf-8 -*-
"""Copia di NewGradCam

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1552lhUWK0EuOPOOx0aKIwCNXRu9dlOsg
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

danielericcobene_imagenet5_path = kagglehub.dataset_download('danielericcobene/imagenet5')
danielericcobene_imagenet_5_path = kagglehub.dataset_download('danielericcobene/imagenet-5')

print('Data source import complete.')

print(danielericcobene_imagenet_5_path)

import os
import torch
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Subset, random_split
import torchvision.transforms as transforms

# Percorso dataset
dataset_path = '/root/.cache/kagglehub/datasets/danielericcobene/imagenet-5/versions/1/imagenet-5/imagenet-5'

# Trasformazioni
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# Carica tutto il dataset (tutte le immagini, tutte le classi)
full_dataset = ImageFolder(root=dataset_path, transform=transform)

# Definisci percentuale train/val
train_ratio = 0.8
train_size = int(train_ratio * len(full_dataset))
val_size = len(full_dataset) - train_size

# Split random (con seed per riproducibilità)
torch.manual_seed(42)
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

print(f"Train dimensions: {len(train_dataset)}")
print(f"Validation dimensions: {len(val_dataset)}")
print(f"Classi: {full_dataset.classes}")

import torch.nn as nn
import torchvision.models as models

# Usa ResNet18 come base per M1
def create_model(num_classes=3):
    model = models.resnet18(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_m1 = create_model(num_classes=3).to(device)

print(model_m1)

# Ottimizzatore e loss
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model_m1.parameters(), lr=1e-3)

def train(model, dataloader, optimizer, criterion, device):
    model.train()
    total_loss = 0.0
    for images, labels in dataloader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(dataloader)
    return avg_loss

def evaluate(model, dataloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct / total

for epoch in range(10):
    train_loss = train(model_m1, train_loader, optimizer, criterion, device)
    val_accuracy = evaluate(model_m1, val_loader, device)
    print(f"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Val Accuracy: {val_accuracy*100:.2f}%")

!pip install torchcam

model_resnet50 = models.resnet50(pretrained=True)  # mantiene le 1000 classi
model_resnet50 = model_resnet50.to(device)
model_resnet50.eval()

from torchcam.methods import GradCAM

cam_m1 = GradCAM(model_m1, target_layer="layer4")
cam_resnet50 = GradCAM(model_resnet50, target_layer="layer4")

def generate_cam_batch(model, cam_extractor, images, device, target_labels=None, use_pred=True):
    model.eval()
    cams = []

    for i in range(images.size(0)):
        image = images[i].unsqueeze(0).to(device)
        output = model(image)

        if use_pred:
            target_class = output.argmax(dim=1).item()
        else:
            if target_labels is None:
                raise ValueError("target_labels must be provided if use_pred=False")
            target_class = target_labels[i].item()

        activation_map = cam_extractor(target_class, output)
        cams.append(activation_map[0].cpu().detach())

    return cams

def binarize_cam(cam, threshold=0.3):
    return (cam >= threshold).float()

def iou(cam1, cam2):
    intersection = (cam1 * cam2).sum()
    union = ((cam1 + cam2) >= 1).float().sum()
    if union == 0:
        return 0.0
    return (intersection / union).item()

def visualize_cam(image_tensor, cam_tensor, title="GradCAM", alpha=0.5):
    from torchvision.transforms.functional import to_pil_image
    from torchcam.utils import overlay_mask
    from matplotlib import cm
    import matplotlib.pyplot as plt

    # Convert image tensor (C, H, W) to PIL
    image = image_tensor.clone().cpu()
    pil_img = to_pil_image(image)

    # Assicurati che la cam sia (H, W) prima dell’interpolazione
    if cam_tensor.dim() == 2:
        cam_tensor = cam_tensor.unsqueeze(0).unsqueeze(0)  # -> (1, 1, H, W)
    elif cam_tensor.dim() == 3:
        cam_tensor = cam_tensor.unsqueeze(0)  # -> (1, C, H, W)

    # Interpolazione a (1, 1, 224, 224)
    cam_resized = torch.nn.functional.interpolate(
        cam_tensor,
        size=(pil_img.height, pil_img.width),  # (H, W)
        mode='bilinear',
        align_corners=False
    )[0, 0]  # Rimuovi batch e channel

    # Overlay e visualizzazione
    result = overlay_mask(pil_img, to_pil_image(cam_resized), alpha=alpha, colormap=cm.inferno)
    plt.imshow(result)
    plt.title(title)
    plt.axis('off')
    plt.show()


ious = []

visualize = True
num_to_visualize = 10
count = 0

for images, labels in val_loader:
    # CAM M1
    cams_m1 = generate_cam_batch(model_m1, cam_m1, images, device, target_labels=labels, use_pred=False)
    # CAM ResNet50
    cams_r50 = generate_cam_batch(model_resnet50, cam_resnet50, images, device, target_labels=labels, use_pred=False)

    for img, lbl, cam1, cam2 in zip(images, labels, cams_m1, cams_r50):
        cam1_bin = binarize_cam(cam1)
        cam2_bin = binarize_cam(cam2)
        iou_score = iou(cam1_bin, cam2_bin)
        ious.append(iou_score)

        if visualize and count < num_to_visualize:
            print(f"[Image {count+1}] True label: {lbl.item()}, IoU: {iou_score:.4f}")
            visualize_cam(img, cam1, title="M1 (ResNet18) - GradCAM")
            visualize_cam(img, cam2, title="ResNet50 - GradCAM")
            count += 1


mean_iou = sum(ious) / len(ious)
print(f"Mean IoU between M1 and ResNet50 GradCAM maps: {mean_iou:.4f}")

